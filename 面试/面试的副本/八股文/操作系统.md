# 操作系统

操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。操作系统存在屏蔽了硬件层的复杂性。 操作系统就像是硬件使用的负责人，统筹着各种相关事项。
操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

## 系统调用：

### cpu指令权限：

程序最终运行的时候实际都会被编译、解释成一条一条的 CPU 指令被 CPU 执行。CPU 指令是做了权限划分的， 例如 Intel X86 中将 CPU 指令权限划分为了 4 个等级：==Ring0、Ring1、Ring2、Ring3==。在 Linux 系统中只有 Ring0 和 Ring3 级别的指令：运行 Ring0 级别指令的叫**内核态**，运行 Ring3 级别指令的叫**用户态**。

<img src="https://s2.loli.net/2022/07/09/qEe4Ov7H8Y6r9lD.jpg" alt="preview" style="zoom:67%;" />

**cpu指令的状态转换方式：**

1. **用户态--->内核态：**唯一途径是通过中断、异常、陷入机制（访管指令）
1. **内核态--->用户态：**设置程序状态字PSW

用户态内核态主要区别在于，处于用户态执行时，<u>进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的</u>。处于内核态执行时，<u>则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的</u>。

什么时候会从用户态转到内核态：

==系统调用、异常、外围设备的中断；==

### 系统调用：

程序基本都是运行在用户态，如果需要调用操作系统提供的系统态级别的子功能就需要系统调用了。

在运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

# 进程与线程：

### 1. 进程（Process）

**进程是资源分配的基本单位**。进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

<img src="https://s2.loli.net/2022/07/09/ruEcIyCQTOqWX4v.png" alt="image-20220318203432832" style="zoom:50%;" />

### 2. 线程（Thread）

线程是**独立调度的基本单位**。一个进程中可以有多个线程，它们共享进程资源。QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

<img src="https://s2.loli.net/2022/07/09/NPvsjGgz1a7Ccx4.png" alt="image-20220318203558056" style="zoom:67%;" />

区别：

1. 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
1. 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
1. 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如<u>内存空间、I/O 设备</u>等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及<u>当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置</u>，而线程切换时只需保存和设置少量寄存器内容，开销很小。
1. 通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

------

### PCB上下文切换

上下文切换，有时也称做进程切换或任务切换，是指CPU从一个进程或线程切换到另一个进程或线程。

在操作系统中，CPU切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态：当前运行任务转为就绪（或者挂起、删除）状态，另一个被选定的就绪任务成为当前任务。==上下文切换包括保存当前任务的运行环境，恢复将要运行任务的运行环境。==

进程上下文用进程的PCB（进程控制块,也称为PCB，即任务控制块）表示，它包括进程状态，CPU寄存器的值等。

在三种情况下可能会发生上下文切换：**中断处理，多任务处理，用户态切换。**在中断处理中，其他程序”打断”了当前正在运行的程序。当CPU接收到中断请求时，会在正在运行的程序和发起中断请求的程序之间进行一次上下文切换。在多任务处理中，CPU会在不同程序之间来回切换，每个程序都有相应的处理时间片，CPU在两个时间片的间隔中进行上下文切换。对于一些操作系统，当进行用户态切换时也会进行一次上下文切换，虽然这不是必须的。

* **上下文是指：当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文。**当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的上下文，以便在再次执行该进程时，能够必得到切换时的状态执行下去。在LINUX中，当前进程上下文均保存在进程的任务数据结构中。在发生中断时,内核就在被中断进程的上下文中，在内核态下执行中断服务例程。但同时会保留所有需要用到的资源，以便中断服务结束时能恢复被中断进程的执行。

### 进程上下文切换和线程上下文切换的区别

进程切换分两步
**1.切换页目录以使用新的地址空间。**
**2.切换内核栈和硬件上下文。**

对于linux来说，线程和进程的最大区别就在于地址空间。
对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。所以明显是进程切换代价大

* 进程上下文切换与线程上下文切换**最主要的区别**就是线程的切换虚拟空间内存是相同的（因为都是属于自己的进程），但是，进程切换的虚拟空间内存则是不同的。

* 同时，这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

------

进程状态的切换：

<img src="https://s2.loli.net/2022/07/09/Mk8I3cteRpfaFsN.png" alt="image-20220318203804830" style="zoom:67%;" />

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源

应该注意以下内容：

- 只有==就绪态和运行态可以相互转换==，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

## 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，<u>按照请求的顺序进行调度</u>。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按<u>估计运行时间最短的顺序进行调度</u>。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

<u>最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。</u> 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。[现代计算机]

**2.1 时间片轮转**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

==时间片轮转算法的效率和时间片的大小有很大关系==：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度**

为每个进程分配一个优先级，<u>按优先级进行调度</u>。为了防止低优先级的进程永远等不到调度，可以**随着时间的推移增加等待进程的优先级**。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。本调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

多级队列是为这种需要连续执行多个时间片的进程考虑，它<u>设置了多个队列，每个队列时间片大小都不同</u>，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

<u>每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程</u>。

<img src="https://s2.loli.net/2022/07/09/olfw34M8dEzk62y.png" alt="image-20220318203819787" style="zoom:67%;" />

### 3. 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程同步

它主要源于进程合作，是进程间共同完成一项任务时直接发生相互作用的关系。为进程之间的直接制约关系。

### 1. 临界区

**对临界资源进行访问**的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 3. 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```java
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

<font size=3> **使用信号量实现生产者-消费者问题** </font> </br>

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，==不能先对缓冲区进行加锁，再测试信号量==。（先锁小再锁大）也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```java
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 4. 管程（Monitors）

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得<u>客户端代码调用更容易</u>。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生产者-消费者问题**

```java
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 经典同步问题

生产者和消费者问题前面已经讨论过了。

### 1. 哲学家进餐问题

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```java
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

### 2. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```java
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

## 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

### 1. 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```java
#include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

<img src="https://s2.loli.net/2022/07/09/CMPAWJ6D3f5jBZ8.png" alt="image-20220318203838032" style="zoom:67%;" />

### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```java
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

<img src="https://s2.loli.net/2022/07/09/CMPAWJ6D3f5jBZ8.png" alt="image-20220318203855048" style="zoom: 67%;" />

### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

### 5. 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

### 6. 套接字Socket

与其它通信机制不同的是，它可用于不同机器间的进程通信。

# 死锁

## 必要条件

<img src="https://s2.loli.net/2022/07/09/YXLMyC2FBK9Hnz4.png" alt="image-20220318203907406" style="zoom:67%;" />

- 互斥：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
- 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
- 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

## 处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

### 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。**当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。**大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

### 死锁检测

==不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。==

1. 每种类型一个资源的死锁检测

<img src="https://s2.loli.net/2022/07/09/NVOpd95zBlyRsj4.png" alt="image-20220318203916649" style="zoom:67%;" />

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

2. 每种类型多个资源的死锁检测

<img src="https://s2.loli.net/2022/07/09/do5SHL8rivJsVZY.png" alt="image-20220318203926692" style="zoom:80%;" />

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
1. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
1. 如果没有这样一个进程，算法终止。

#### 死锁恢复

- **立即结束所有进程的执行，重新启动操作系统** ：这种方法简单，但以前所在的工作全部作废，损失很大。
- **撤销涉及死锁的所有进程，解除死锁后继续运行** ：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
- **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
- **抢占资源** ：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。

### 死锁预防

在程序运行之前预防发生死锁。

1. 破坏互斥条件：例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。但很多资源往往是不能同时访问的；

1. 破坏占有和等待条件：
   1. 静态分配策略：一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。

1. 破坏不可抢占条件：运用剥夺式调度算法，但剥夺式调度方法目前一般仅适用于 **主存资源** 和 **处理器资源** 的分配，并不适用于所以的资源，会导致 **资源利用率下降**。

1. 破坏环路等待：
   1. 层次分配策略：所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的，因为那样的话，就出现了已经申请了较高层的资源，反而去申请了较低层的资源，不符合层次分配策略

### 死锁避免

我们将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在未申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。那么如何保证系统保持在安全状态呢？通过算法，其中最具有代表性的 **避免死锁算法** 就是 Dijkstra 的银行家算法。（类似上文的死锁避免中的具有多种类型的死锁资源的死锁检测）

<img src="https://s2.loli.net/2022/07/09/7vhclFpRjQZwg8Y.png" alt="image-20220318203940065" style="zoom: 80%;" />



# 内存管理

内存管理包括：1.内存的分配与回收 2.地址转换

## 常见的内存管理机制：

**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理** ：块式管理是远古的计算机操作系统的内存管理方式，很容易产生碎片造成浪费。

1. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。

   > 将==内存空间==分为一个个大小相等的分区（例如4KB），每个分区就是一个页框或称页帧（Page Frame）。每个页框有一个编号被称为页框号（从0开始）。将==用户进程的地址空间==也分为于页框大小相等的一个个区域，称为页或者页面，每个页面也有一个页号（也是从0开始）。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。
   >
   > 如何根据逻辑地址计算物理地址：
   >
   > 1. 算出逻辑地址对应的页号（页号=逻辑地址/页面长度）；
   > 1. 知道该页号对应页面在内存中的起始地址（页内偏移量=逻辑地址%页面长度）；
   > 1. 算出逻辑地址在页面内的“偏移量”；
   > 1. 物理地址=页面始址+页内偏移量；
   >
   > 注：由于物理地址和逻辑地址的页内偏移量相同，因此修改的时候只需要修改高位地址（即修改页号为页框号）；
   >
   > ![image-20220318203959157](https://s2.loli.net/2022/07/09/v2ad8f9sDcueFxz.png)

1. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 ==段式管理把主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。== 段式管理通过段表对应逻辑地址和物理地址。

1. **段页式管理**：

分页式管理中，有两点很重要：

> 1. 虚拟地址到物理地址转换要快；//快表
> 1. 解决虚拟空间大，页表也会很大的问题；//多级页表

#### TLB 快表：

Translation lookaside buffer 解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把<u>快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。</u>作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
1. 如果该页在快表中，直接从快表中读取相应的物理地址；
1. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
1. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景

分页机制和分段机制的共同点和区别

1. 共同点
   - 分页机制和分段机制都是为了**提高内存利用率，减少内存碎片**。
   - 页和段都是**离散存储**的，所以两者都是离散分配内存的方式。但是，**每个页和段中的内存是连续**的。
1. 区别
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而**段是逻辑信息的单位**，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。
   - 地址空间的维度：分页是一维地址空间，**分段是二维**的。
   - 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

## 虚拟内存

虚拟内存的目的是为了让**物理内存扩充成更大的逻辑内存**，从而让程序获得更多的可用内存。他有如下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

虚拟内存的定义：

通过 **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

### 局部性原理：

是虚拟内存技术的基础，因为程序具有局部性原理，才可以只装入部分程序到内存就开始运行。他主要表现在：

- 时间局部性：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
- 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。









## 分页系统地址映射

内存管理单元（MMU）CPU芯片中的一个硬件模块，负责虚拟内存地址管理、内存保护等功能。如果处理器启用了MMU，CPU执行单元发出的内存地址将被MMU截获，从CPU到MMU的地址称为虚拟地址（**Virtual Address**，以下简称**VA**），而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将VA映射成PA（**Physical Address**）。其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。==一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。==

1. 一个进程对应一张页表；
1. 进程的每一页对应一个页表项；
1. 每个页表项由“页号”和“块号”组成；
1. 页表记录进程页面和实际存放的内存块之间的对应关系；
1. 每个页表项的长度是相同的，页号是隐含的；
   - 因为页号可以计算得到：由物理内存的大小+页面大小，我们可以知道多少位的物理地址才可以表达所有的物理页面，这些位数凑整为8bit的倍数就是页表项长度。此时只需要再加上页表存放的起始地址就可以知道各页号对应的页表项存放的位置；
   - <img src="https://s2.loli.net/2022/07/09/tUe84KhxnmqMT6a.png" alt="image-20220318204011655" style="zoom: 50%;" />

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。**例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。**

![image-20220318204035568](https://s2.loli.net/2022/07/09/Jie8zWfkPSc1mC3.png)

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1. 最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。==LRU 将最近最久未使用的页面换出==。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为<u>每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。</u>

```
4，7，0，7，1，0，1，2，1，2，6
```

<img src="https://s2.loli.net/2022/07/09/8VbFegRIPh6sa1c.png" alt="image-20220318204042381" style="zoom:67%;" />

### 3. 最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；**如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。**

<img src="https://s2.loli.net/2022/07/09/8MHweodPAn3EaNu.png" alt="image-20220318204053175" style="zoom:67%;" />

### 6. 时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

<img src="https://s2.loli.net/2022/07/09/kOjML9noabQS1pJ.png" alt="image-20220318204127426" style="zoom:67%;" />



# 设备管理：

## 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

<img src="https://s2.loli.net/2022/07/09/LgjSr9QJqdmKwNR.png" alt="image-20220318204140733" style="zoom:67%;" />

## 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，==寻道时间最长==，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

### 1. 先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

### 2. 最短寻道时间优先

> SSTF, Shortest Seek Time First

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，**两端的磁道请求更容易出现饥饿现象**。

<img src="https://s2.loli.net/2022/07/09/CX4RnQlGOMbV2mN.png" alt="image-20220318204150525" style="zoom:67%;" />

### 3. 电梯算法

> SCAN

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

<img src="https://s2.loli.net/2022/07/09/5Kma8jVyMxnschY.png" alt="image-20220318204159408" style="zoom:67%;" />

# IO

目前Linux系统中提供了5种IO处理模型

1. 阻塞IO：当发起一次IO操作后一直等待成功或失败之后才返回，在这期间程序不能做其它的事情。

1. 非阻塞IO：发起一次IO操作后立刻返回值，如果数据访问失败则返回一个ERROR，数据会尝试访问直到访问成功（占用CPU）

1. IO多路复用：==IO多路复用在Linux下包括了三种，select、poll、epoll==。Java NIO实际上就是多路复用IO。在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

   > ![image-20220329145206850](https://s2.loli.net/2022/07/09/yEWhlquLkVdrUwF.png)
   >
   > **select:**
   >
   > select的调用会阻塞到有文件描述符可以进行IO操作或被信号打断或者超时才会返回。
   >
   > select将监听的文件描述符分为三组，每一组监听不同的需要进行的IO操作。readfds是需要进行读操作的文件描述符，writefds是需要进行写操作的文件描述符，exceptfds是需要进行异常事件处理的文件描述符。这三个参数可以用NULL来表示对应的事件不需要监听。
   >
   > 当select返回时，每组文件描述符会被select过滤，只留下可以进行对应IO操作的文件描述符。
   >
   > **poll:**
   >
   > poll只有一个pollfd数组，数组中的每个元素都表示一个需要监听IO操作事件的文件描述符。events参数是我们需要关心的事件，revents是所有内核监测到的事件。
   >
   > **epoll:**
   >
   > epoll_create&epoll_create1用于创建一个epoll实例，而epoll_ctl用于往epoll实例中增删改要监测的文件描述符，epoll_wait则用于阻塞的等待可以执行IO操作的文件描述符直到超时。

1. 信号驱动IO：当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。

1. 异步IO：用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它收到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要知道实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。









# 题目：

什么是通道：

通道是一种通过执行通道程序管理I/O操作的控制器，它使主机（CPU和内存）与I/O操作之间达到更高的并行程度。由于它的任务是管理实现输入/输出操作，提供一种传送通道，所以将这种部件称作“通道”。

1.进程间通信的方式：

进程通信的**目的**：

1. 数据传输：一个进程需要将它的数据发送给另一个进程;
1. 资源共享：多个进程之间共享同样的资源;
1. 通知事件：一个进程需要向另一个或一组进程发送消息，通知它们发生了某种事件;
1. 进程控制：有些进程希望完全控制另一个进程的执行(如Debug进程)，该控制进程希望能够拦截另一个进程的所有操作，并能够及时知道它的状态改变。

进程间通信的**原理**：

每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过==内核==，在<u>内核中开辟一块缓冲区</u>，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信机制。

进程间通信的几种方式：

1. 管道（pipe）
1. 命名管道（FIFO）
1. 消息队列（msg）
1. 信号量（sem）
1. 共享内存(shm)

2.线程挂了，对应的锁会释放吗？



概述：

网络：许多计算机连接在一起

互联网：许多网络连接在一起

因特网：Internet：全球最大的一个互联网



内存的静态分配和动态分配的区别：

1. 时间：静态分配发生在程序编译和连接的时候。动态分配则发生在程序调入和执行的时候。即静态内存是在程序一开始运行就会分配内存，直到程序结束了，内存才被释放。动态内存是在程序调用在程序中定义的函数时才被分配，函数调用结束了，动态内存就释放。
1. 空间：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由函数malloc进行分配。**不过栈的动态分配和堆不同，他的动态分配是由编译器进行释放，无需我们手工实现**。

一个进程的内存空间而言，可以在逻辑上分成3个部份：**代码区**，**静态数据区**和**动态数据区**。

 动态数据区一般就是“堆栈”。“栈(stack)”和“堆(heap)”是两种不同的动态数据区，栈是一种线性结构，堆是一种链式结构。进程的每个线程都有私有的“栈”，所以每个线程虽然代码一样，但本地变量的数据都是互不干扰。一个堆栈可以通过“基地址”和“栈顶”地址来描述。**全局变量和静态变量分配在静态数据区，本地变量分配在动态数据区**，即堆栈中。程序通过堆栈的基地址和偏移量来访问本地变量。

动态内存分配，相对于静态内存分配，有如下优点：

1. 不需要预先分配存储空间；
1. 分配的空间可以根据程序的需要扩大或缩小；



